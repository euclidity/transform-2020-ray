{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unleash the Ray - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dependencies we have already seen...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-11 11:37:26,802\tINFO resource_spec.py:204 -- Starting Ray with 35.3 GiB memory available for workers and up to 17.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-11 11:37:27,097\tINFO services.py:1168 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.39',\n",
       " 'raylet_ip_address': '192.168.1.39',\n",
       " 'redis_address': '192.168.1.39:18030',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-11_11-37-26_771023_38101/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-11_11-37-26_771023_38101/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-11_11-37-26_771023_38101'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=6, num_gpus=0, include_webui=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialisation the [Ray Dashboard](https://docs.ray.io/en/master/ray-dashboard.html) is available on the **webui_url** port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some raytune compatible training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# differences from what we've seen before, this is an end to end training function\n",
    "# where we are loading the dataset running our complete train and test loop whilst\n",
    "# \n",
    "def e2e_simple_training(config):\n",
    "    \n",
    "    #threadsafe\n",
    "    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    \n",
    "    # chose your CV strategy\n",
    "    splitter = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # run k fold training and testing\n",
    "    f1_scores = [] # keep hold of all individual scores\n",
    "    for train_ind, test_ind in splitter.split(X, y):\n",
    "        pipeline = make_pipeline(RobustScaler(),\n",
    "                                  RandomForestClassifier(random_state=42))\n",
    "\n",
    "        pipeline.set_params(**config)\n",
    "        pipeline.fit(X[train_ind], y[train_ind])\n",
    "        \n",
    "        y_pred = pipeline.predict(X[test_ind])\n",
    "        \n",
    "        f1_scores.append(f1_score(y_pred, y[test_ind]))\n",
    "    \n",
    "    # use tunes reporter\n",
    "    tune.track.log(mean_f1_score=np.array(f1_scores).mean(),\n",
    "                std_f1_score=np.array(f1_scores).std(),\n",
    "                # and we can actually add any metrics we like\n",
    "                done=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [1,5,15,50,100],\n",
    "    'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "    'randomforestclassifier__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO convert this to a set of ray search spaces\n",
    "\n",
    "The Ray config object is freeform, we imprint our own structure.\n",
    "\n",
    "However, tunable parameters need to be represented by tune distribution object >> [read the docs](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html?highlight=tune.grid#random-distributions-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_tuning_config = {\n",
    "    'randomforestclassifier__n_estimators': tune.grid_search([1,5,15,50,100])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "                e2e_simple_training,\n",
    "                config=ray_tuning_config,\n",
    "                resources_per_trial=dict(cpu=1, gpu=0),\n",
    "                local_dir=\"~/ray_results/grid_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe()\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"mean_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def plot_some_tune_results(df):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16,6))\n",
    "    x = np.linspace(0.85, 1.0, 100)\n",
    "\n",
    "    n_estimators = df['config/randomforestclassifier__n_estimators'].values.tolist()\n",
    "\n",
    "    lines = []\n",
    "    for mu, sigma in zip(df['mean_f1_score'], df['std_f1_score']):\n",
    "        pdf = norm.pdf(x, mu, sigma)\n",
    "        line, = ax.plot(x, pdf, alpha=0.6)\n",
    "        ax.axvline(mu, color=line.get_color())\n",
    "        ax.text(mu, pdf.max(), f\"{mu:.3f}\", color=line.get_color(), fontsize=14)\n",
    "        lines.append(line)\n",
    "\n",
    "    plt.legend(handles=lines, labels=n_estimators, title=\"n estimators\")\n",
    "    ax.set_title(f\"Average F1 Scores\")\n",
    "    \n",
    "plot_some_tune_results(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really increase the size of the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 6D search space - 960 combinations - 4800 calls to fit\n",
    "#\n",
    "\n",
    "ray_tuning_config = {\n",
    "    'randomforestclassifier__n_estimators': tune.grid_search([1,5,15,50,100]),\n",
    "    'randomforestclassifier__criterion': tune.grid_search(['gini', 'entropy']),\n",
    "    'randomforestclassifier__max_features': tune.grid_search(['auto', 'sqrt', 'log2']),\n",
    "#     'randomforestclassifier__bootstrap': tune.grid_search([True, False]),\n",
    "#     'randomforestclassifier__min_samples_leaf': tune.grid_search([1,2,3,4]),\n",
    "#     'randomforestclassifier__min_samples_split': tune.grid_search([3,4,5,6])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "                e2e_simple_training,\n",
    "                config=ray_tuning_config,\n",
    "                resources_per_trial=dict(cpu=1, gpu=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"mean_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe()\n",
    "top_n_df = df.nlargest(10, \"mean_f1_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_some_tune_results(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.display(height=1000) \n",
    "%tensorboard --logdir \"~/ray_results/grid_search\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you are all done, shutdown Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exit\n",
    "\n",
    "So what have we just done?\n",
    " - shown how the performance of a model with a single set of hyperparameters affects our score\n",
    " - shown that kfold cv can give us a picture of that distribution which is easier to compute that out-of-bootstrap scores and has less leakage\n",
    " - so which model to choose? == in this case which data split, which is not what we want, we want to chose a robust estimator so we want to find a model with the best score distribution for a given set of hyperparameters\n",
    " - (note: if we want to do hyperparaemter tuning and want our model selection to be unbiaesed weshould do nested Cross Validaiton, but for simpliciy of the code we are sticking with kfold. See: xxxxx_xxxx_xx.ipynb for the nested cross validaiton example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
